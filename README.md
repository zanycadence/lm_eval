# LmEval - Language Model Evaluation Tools

Evaluating language models across the wide variety of performance metrics is non-trivial. The goal of this project is to provide support for a variety of Language Model Evaluation tools and datasets and the ability to track and monitor model performance across each of the metrics.

***This is a work in progress***


## Installation

If [available in Hex](https://hex.pm/docs/publish), the package can be installed
by adding `lm_eval` to your list of dependencies in `mix.exs`:

```elixir
def deps do
  [
    {:lm_eval, "~> 0.1.0"}
  ]
end
```

Documentation can be generated with [ExDoc](https://github.com/elixir-lang/ex_doc)
and published on [HexDocs](https://hexdocs.pm). Once published, the docs can
be found at <https://hexdocs.pm/lm_eval>.

